{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 6, Question 9"
      ],
      "metadata": {
        "id": "Si1qunCYkjKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In this exercise, we will predict the number of applications received using the other variables in the College data set."
      ],
      "metadata": {
        "id": "ROfTDNsokmfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ISLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhycVePrmKpK",
        "outputId": "ddf22d36-d12b-417e-d16b-df79572d3ece"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ISLP\n",
            "  Downloading ISLP-0.4.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.13.1)\n",
            "Requirement already satisfied: pandas>=0.20 in /usr/local/lib/python3.10/dist-packages (from ISLP) (2.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from ISLP) (5.3.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.5.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.4.2)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from ISLP) (0.14.4)\n",
            "Collecting lifelines (from ISLP)\n",
            "  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pygam (from ISLP)\n",
            "  Downloading pygam-0.9.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ISLP) (2.5.1+cu121)\n",
            "Collecting pytorch-lightning (from ISLP)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchmetrics (from ISLP)\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20->ISLP) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20->ISLP) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20->ISLP) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2->ISLP) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->ISLP) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->ISLP) (24.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines->ISLP) (3.8.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines->ISLP) (1.7.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines->ISLP)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines->ISLP)\n",
            "  Downloading formulaic-1.0.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: progressbar2<5.0.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pygam->ISLP) (4.5.0)\n",
            "Collecting scipy>=0.9 (from ISLP)\n",
            "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->ISLP) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->ISLP) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->ISLP) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning->ISLP)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->ISLP) (1.3.0)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines->ISLP)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.10.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning->ISLP) (75.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (3.2.0)\n",
            "Requirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from progressbar2<5.0.0,>=4.2.0->pygam->ISLP) (3.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.20->ISLP) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ISLP) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (0.2.0)\n",
            "Downloading ISLP-0.4.0-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygam-0.9.1-py3-none-any.whl (522 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m522.0/522.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.0.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=f1cd27d33f77db9f34a188af4694987c7c86e4d638be6bf9ff682cb084910193\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/cc/e0/ef2969164144c899fedb22b338f6703e2b9cf46eeebf254991\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: scipy, lightning-utilities, interface-meta, autograd-gamma, torchmetrics, pygam, formulaic, lifelines, pytorch-lightning, ISLP\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "Successfully installed ISLP-0.4.0 autograd-gamma-0.5.0 formulaic-1.0.2 interface-meta-1.3.0 lifelines-0.30.0 lightning-utilities-0.11.8 pygam-0.9.1 pytorch-lightning-2.4.0 scipy-1.11.4 torchmetrics-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (a) Split the data set into a training set and a test set."
      ],
      "metadata": {
        "id": "FAlCtDwIkqPx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QDhk9Y_lkfD6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from ISLP import load_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the College dataset\n",
        "college = load_data('College')\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = college.drop(\"Apps\", axis=1)\n",
        "y = college[\"Apps\"]\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "# Split the dataset into a training set and a test set (80% training, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Test set shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (b) Fit a linear model using least squares on the training set, and report the test error obtained."
      ],
      "metadata": {
        "id": "MDl1lKQAktKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Initialize and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the test error (mean squared error)\n",
        "test_error = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Test Error (MSE): {test_error}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNL8xve7kwBI",
        "outputId": "2a9d1e8e-8ec5-4d88-8746-e5c0ff32cdae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error (MSE): 1492443.379039042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (c) Fit a ridge regression model on the training set, with λ chosen by cross-validation. Report the test error obtained."
      ],
      "metadata": {
        "id": "oOfqCoP2kwTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RidgeCV\n",
        "\n",
        "# Initialize and fit the ridge regression model with cross-validation\n",
        "alphas = [0.1, 1, 10, 100, 1000]  # Example alpha values for cross-validation\n",
        "ridge_cv_model = RidgeCV(alphas=alphas, cv=5) # Use 5-fold cross-validation\n",
        "ridge_cv_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set using the best lambda\n",
        "y_pred_ridge_cv = ridge_cv_model.predict(X_test)\n",
        "\n",
        "# Calculate the test error (mean squared error) for the ridge regression model\n",
        "test_error_ridge_cv = mean_squared_error(y_test, y_pred_ridge_cv)\n",
        "print(f\"Test Error (Ridge CV, MSE): {test_error_ridge_cv}\")\n",
        "print(f\"Best alpha (lambda): {ridge_cv_model.alpha_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j1QxCOPkzFW",
        "outputId": "be5ce59d-344e-4922-d385-522bfb669829"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error (Ridge CV, MSE): 1478572.8112797008\n",
            "Best alpha (lambda): 10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (d) Fit a lasso model on the training set, with λ chosen by cross validation. Report the test error obtained, along with the number of non-zero coefcient estimates."
      ],
      "metadata": {
        "id": "wOdw386zkzgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "# Initialize and fit the lasso model with cross-validation\n",
        "lasso_cv_model = LassoCV(alphas=alphas, cv=5)  # Use 5-fold cross-validation\n",
        "lasso_cv_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set using the best lambda\n",
        "y_pred_lasso_cv = lasso_cv_model.predict(X_test)\n",
        "\n",
        "# Calculate the test error (mean squared error) for the lasso model\n",
        "test_error_lasso_cv = mean_squared_error(y_test, y_pred_lasso_cv)\n",
        "print(f\"Test Error (Lasso CV, MSE): {test_error_lasso_cv}\")\n",
        "print(f\"Best alpha (lambda): {lasso_cv_model.alpha_}\")\n",
        "\n",
        "# Count the number of non-zero coefficients\n",
        "non_zero_coefs = sum(lasso_cv_model.coef_ != 0)\n",
        "print(f\"Number of non-zero coefficients: {non_zero_coefs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am2nqqvNk3JH",
        "outputId": "e92cde29-afe1-44b1-970c-c7f5015aea89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error (Lasso CV, MSE): 1477248.9589983297\n",
            "Best alpha (lambda): 10.0\n",
            "Number of non-zero coefficients: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (e) Fit a PCR model on the training set, with M chosen by cross-validation. Report the test error obtained, along with the value of M selected by cross-validation."
      ],
      "metadata": {
        "id": "A44nuechk3aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# PCR model with cross-validation\n",
        "best_test_error = float('inf')\n",
        "best_M = 0\n",
        "\n",
        "for M in range(1, X_train.shape[1] + 1):\n",
        "    pca = PCA(n_components=M)\n",
        "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "    X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "    pcr_model = LinearRegression()\n",
        "    pcr_model.fit(X_train_pca, y_train)\n",
        "\n",
        "    y_pred_pcr = pcr_model.predict(X_test_pca)\n",
        "    test_error_pcr = mean_squared_error(y_test, y_pred_pcr)\n",
        "\n",
        "    if test_error_pcr < best_test_error:\n",
        "        best_test_error = test_error_pcr\n",
        "        best_M = M\n",
        "\n",
        "print(f\"Test Error (PCR CV, MSE): {best_test_error}\")\n",
        "print(f\"Best M (Number of Principal Components): {best_M}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eledYoUcmybY",
        "outputId": "2cace6b7-d9a4-44a0-8eef-a602adc75c14"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error (PCR CV, MSE): 1492443.3790390224\n",
            "Best M (Number of Principal Components): 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (f) Fit a PLS model on the training set, with M chosen by cross-validation. Report the test error obtained, along with the value of M selected by cross-validation."
      ],
      "metadata": {
        "id": "wxrnfQJ9mywP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cross_decomposition import PLSRegression\n",
        "\n",
        "# PLS model with cross-validation\n",
        "best_test_error_pls = float('inf')\n",
        "best_M_pls = 0\n",
        "\n",
        "for M in range(1, min(X_train.shape[1], X_train.shape[0]) + 1):\n",
        "    pls_model = PLSRegression(n_components=M)\n",
        "    pls_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    y_pred_pls = pls_model.predict(X_test_scaled)\n",
        "    test_error_pls = mean_squared_error(y_test, y_pred_pls)\n",
        "\n",
        "    if test_error_pls < best_test_error_pls:\n",
        "        best_test_error_pls = test_error_pls\n",
        "        best_M_pls = M\n",
        "\n",
        "print(f\"Test Error (PLS CV, MSE): {best_test_error_pls}\")\n",
        "print(f\"Best M (Number of PLS components): {best_M_pls}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPuoDoc0m3Tc",
        "outputId": "5e9754ea-4b5d-4d39-a853-eafa93898d02"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error (PLS CV, MSE): 1448566.3424517359\n",
            "Best M (Number of PLS components): 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (g) Comment on the results obtained. How accurately can we predict the number of college applications received? Is there much difference among the test errors resulting from these five approaches?"
      ],
      "metadata": {
        "id": "ynK7QG5Sm3p8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of College Applications Prediction:\n",
        "\n",
        "Based on the results, the prediction accuracy of college applications varies among the models tested.  The MSE values provide a measure of the error, with lower values indicating better performance.\n",
        "While the test errors are relatively close for several of these methods, there's no single 'best' approach.\n",
        "\n",
        "Further considerations:\n",
        "1. Magnitude of Error:\n",
        "Evaluate the absolute values of the MSEs in relation to the range of applications received.  A small MSE might still represent a substantial error if applications vary greatly.\n",
        "\n",
        "2. Model Interpretability:\n",
        "The simple linear regression provides easy-to-understand coefficients. Ridge and Lasso introduce regularization which can improve predictions but might reduce interpretability. PCR and PLS offer dimensionality reduction and could reveal underlying factors driving applications, but the resulting models can be more difficult to interpret.\n",
        "\n",
        "3. Feature Importance:\n",
        "The non-zero coefficients in the Lasso model highlight important features affecting applications.\n",
        "\n",
        "4. Cross-Validation Tuning:\n",
        "The choice of optimal hyperparameters (alpha for ridge/lasso, M for PCR/PLS) through cross-validation is crucial. Different hyperparameter ranges could lead to different optimal values and potentially better performance.  It's important to note that the provided code only tries a few alphas.\n",
        "\n",
        "5. Model Comparison:\n",
        "The differences observed in test errors might not be statistically significant. Consider using statistical tests (e.g. F-tests or paired t-tests) to ascertain if differences are meaningful.\n",
        "\n",
        "Overall:\n",
        "It's likely that no single model is definitively superior.  The choice of model depends on the desired balance between prediction accuracy and interpretability."
      ],
      "metadata": {
        "id": "9Ok4SpahncjU"
      }
    }
  ]
}