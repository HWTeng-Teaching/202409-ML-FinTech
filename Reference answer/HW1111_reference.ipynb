{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gNg6B4P2UVp7",
        "1h6GYYA2V0C1",
        "uJ_SZ09rXFLq",
        "qtthX6aOQT3_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Machine Learning and FinTech 2024/25\n",
        "##Homework 1111 reference answer\n",
        "By TA, Chan Nok Hang"
      ],
      "metadata": {
        "id": "vwgWYcgAdNmr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Name    | HWCODE    | Assignment |\n",
        "|---------|-----------|------------|\n",
        "| Sabrina | HW1111Q1  | Ch06_Q3    |\n",
        "| Rebecca | HW1111Q2  | Ch06_Q4    |\n",
        "| Pinyo   | HW1111Q3  | Ch06_Q8    |\n",
        "| Hampus  | HW1111Q4  | Ch06_Q9    |"
      ],
      "metadata": {
        "id": "sFZTIbW6RVO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ch6_Q3\n",
        "3. Suppose we estimate the regression coefficients in a linear regression model by minimizing\n",
        "$$\\sum_{i=1}^n(y_i-\\beta_0-\\sum_{j=1}^p\\beta_jx_{ij})^2 \\text{subject to} \\sum_{j=1}^p |\\beta_j|\\le S$$\n",
        "for a particular value of s. For parts (a) through (e), indicate which\n",
        " of i. through v. is correct. Justify your answer."
      ],
      "metadata": {
        "id": "gNg6B4P2UVp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(a)\n",
        "As we increase s from 0, the training RSS will:\\\n",
        " i. Increase initially, and then eventually start decreasing in an\n",
        " inverted U shape.\\\n",
        " ii. Decrease initially, and then eventually start increasing in a\n",
        " U shape.\\\n",
        " iii. Steadily increase.\\\n",
        " iv. Steadily decrease.\\\n",
        " v. Remain constant."
      ],
      "metadata": {
        "id": "jtWjf8GTfaKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: iv. Steadily decrease. When s=0, all coefficients $β_j$ are forced to be zero, so the model predicts only the intercept $β_0$ (model can’t fit the data well without features), yielding high training RSS.\n",
        "\n",
        "As s increases, more flexibility is allowed in the coefficients, reducing\n",
        "the training RSS because the model can fit the data better."
      ],
      "metadata": {
        "id": "T4Fgyp7nfsqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(b)\n",
        "Repeat (a) for test RSS."
      ],
      "metadata": {
        "id": "dfZfq6iMfmWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: ii. Decrease initially, and then eventually start increasing in a U\n",
        "shape.\n",
        "Explanation:\n",
        "With very low s, the model is too constrained, resulting in underfitting\n",
        "and high test RSS. As s increases, the model can fit the data better, reducing\n",
        "test RSS. However, after a certain point, further increasing s leads to\n",
        "overfitting, causing test RSS to rise again."
      ],
      "metadata": {
        "id": "qUyx9spcftfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(c)\n",
        "Repeat (a) for variance."
      ],
      "metadata": {
        "id": "MdIolX66fqp4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: iv. Steadily increase.\n",
        "Explanation:\n",
        "With a small s, the coefficients (βj) are heavily constrained, leading to\n",
        "low variance. As s increases, the model has more flexibility, causing higher\n",
        "variance in the estimated coefficients (may lead to overfitting)."
      ],
      "metadata": {
        "id": "Lp82qtwwIno4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(d)\n",
        "Repeat (a) for (squared) bias."
      ],
      "metadata": {
        "id": "e4lQk8DKIkdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: ii. Decrease initially, and then eventually start increasing in a U shape. Explanation:\n",
        "At very low s, the model is overly simplistic (highly biased). Increasing s reduces bias as the model becomes more flexible. However, too large s may cause the model to capture noise, which could indirectly affect the model's ability to generalize, potentially increasing bias slightly due to overfitting."
      ],
      "metadata": {
        "id": "pXmep4aaIppZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(e)\n",
        "Repeat (a) for the irreducible error."
      ],
      "metadata": {
        "id": "ISZDwgwlIpbX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: v. Remain constant. Explanation:\n",
        "The irreducible error is due to inherent noise in the data and cannot be affected by the model or the choice of s. Therefore, it remains constant regardless of s."
      ],
      "metadata": {
        "id": "2fmDW257IuWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ch6_Q4\n",
        "4. Suppose we estimate the regression coefficients in a linear regression model by minimizing\n",
        "$$\\sum_{i=1}^n(y_i-\\beta_0-\\sum_{j=1}^p\\beta_jx_{ij})^2 + \\lambda \\sum_{j=1}^p \\beta_j^2$$\n",
        "for a particular value of s. For parts (a) through (e), indicate which of i. through v. is correct. Justify your answer."
      ],
      "metadata": {
        "id": "1h6GYYA2V0C1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(a)\n",
        "As we increase $\\lambda$ from 0, the training RSS will:\\\n",
        " i. Increase initially, and then eventually start decreasing in an\n",
        " inverted U shape.\\\n",
        " ii. Decrease initially, and then eventually start increasing in a\n",
        " U shape.\\\n",
        " iii. Steadily increase.\\\n",
        " iv. Steadily decrease.\\\n",
        " v. Remain constant."
      ],
      "metadata": {
        "id": "PwrTP99nqexv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: iii. Steadily increase.\n",
        "\n",
        "Higher $\\lambda$ leads to simpler models that may underfit, increasing training error. As $\\lambda$ increases, regularization shrinks $\\beta_j$, reducing the model's flexibility.\n"
      ],
      "metadata": {
        "id": "emA-x3syqex_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(b)\n",
        "Repeat (a) for test RSS."
      ],
      "metadata": {
        "id": "8OwprWNVqeyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: ii. Decrease initially, and then eventually start increasing in a U shape.\n",
        "\n",
        "Test RSS typically decreases initially (reduced overfitting) but increases later (underfitting) as $\\lambda$ grows.\n"
      ],
      "metadata": {
        "id": "I4DWplNTqeyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(c)\n",
        "Repeat (a) for variance."
      ],
      "metadata": {
        "id": "jrmUTxvoqeyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: iv. Steadily decrease\n",
        "\n",
        "Variance decreases as $\\lambda$ grows because the model becomes less sensitive to small changes in the data.\n"
      ],
      "metadata": {
        "id": "HIn7jhD6qeyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(d)\n",
        "Repeat (a) for (squared) bias."
      ],
      "metadata": {
        "id": "PCmkvDeHqeyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: iv. Steadily increase.\n",
        "\n",
        "Bias increases with larger $\\lambda$ since the model becomes too simple and underfits."
      ],
      "metadata": {
        "id": "Yvo7y8jHqeyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(e)\n",
        "Repeat (a) for the irreducible error."
      ],
      "metadata": {
        "id": "K4S8fUjRqeyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: v. Remain constant\n",
        "\n",
        "Irreducible error is inherent in the data and does not depend on $\\lambda$."
      ],
      "metadata": {
        "id": "bO5OnbVTqeyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ch6_Q8\n",
        "8. In this exercise, we will generate simulated data, and will then use this data to perform forward and backward stepwise selection."
      ],
      "metadata": {
        "id": "uJ_SZ09rXFLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(a)\n",
        "Create a random number generator and use its normal() method to generate a predictor X of length n = 100, as well as a noise vector ε of length n = 100."
      ],
      "metadata": {
        "id": "1Ojvz9cmQknk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4c73351-5721-4e7a-874f-96ac7b9c9b72",
        "outputId": "07fbb069-310c-4ceb-e193-e3761b8da7f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.49671415, -0.1382643 ,  0.64768854,  1.52302986, -0.23415337,\n",
              "       -0.23413696,  1.57921282,  0.76743473, -0.46947439,  0.54256004,\n",
              "       -0.46341769, -0.46572975,  0.24196227, -1.91328024, -1.72491783,\n",
              "       -0.56228753, -1.01283112,  0.31424733, -0.90802408, -1.4123037 ,\n",
              "        1.46564877, -0.2257763 ,  0.0675282 , -1.42474819, -0.54438272,\n",
              "        0.11092259, -1.15099358,  0.37569802, -0.60063869, -0.29169375,\n",
              "       -0.60170661,  1.85227818, -0.01349722, -1.05771093,  0.82254491,\n",
              "       -1.22084365,  0.2088636 , -1.95967012, -1.32818605,  0.19686124,\n",
              "        0.73846658,  0.17136828, -0.11564828, -0.3011037 , -1.47852199,\n",
              "       -0.71984421, -0.46063877,  1.05712223,  0.34361829, -1.76304016,\n",
              "        0.32408397, -0.38508228, -0.676922  ,  0.61167629,  1.03099952,\n",
              "        0.93128012, -0.83921752, -0.30921238,  0.33126343,  0.97554513,\n",
              "       -0.47917424, -0.18565898, -1.10633497, -1.19620662,  0.81252582,\n",
              "        1.35624003, -0.07201012,  1.0035329 ,  0.36163603, -0.64511975,\n",
              "        0.36139561,  1.53803657, -0.03582604,  1.56464366, -2.6197451 ,\n",
              "        0.8219025 ,  0.08704707, -0.29900735,  0.09176078, -1.98756891,\n",
              "       -0.21967189,  0.35711257,  1.47789404, -0.51827022, -0.8084936 ,\n",
              "       -0.50175704,  0.91540212,  0.32875111, -0.5297602 ,  0.51326743,\n",
              "        0.09707755,  0.96864499, -0.70205309, -0.32766215, -0.39210815,\n",
              "       -1.46351495,  0.29612028,  0.26105527,  0.00511346, -0.23458713])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "X = np.random.normal(0, 1, 100)\n",
        "epsilon = np.random.normal(0, 1, 100)\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(b)\n",
        "Generate a response vector Y of length n = 100 according to the model\n",
        "$$Y = \\beta_0+ \\beta_1X+ \\beta_2X^2+ \\beta_3X^3+\\epsilon,$$\n",
        " where $\\beta_0$, $\\beta_1$, $\\beta_2$, and $\\beta_3$ are constants of your choice."
      ],
      "metadata": {
        "id": "cIvtM9RrQrAe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0bc985c-27a7-4b73-b20d-6639ba827de6"
      },
      "outputs": [],
      "source": [
        "# Set the number of observations (n)\n",
        "n = 100\n",
        "\n",
        "# Set the coefficients (β0, β1, β2, β3)\n",
        "beta0 = 2\n",
        "beta1 = 3\n",
        "beta2 = -0.5\n",
        "beta3 = 0.2\n",
        "\n",
        "# Generate the response vector Y\n",
        "Y = beta0 + beta1*X + beta2*X**2 + beta3*X**3 + np.random.normal(size=n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(c)\n",
        "Use forward stepwise selection in order to select a model containing the predictors $X,X^2,...,X^{10}$. What is the model obtained according to $C_p$? Report the coefficients of the model obtained."
      ],
      "metadata": {
        "id": "EPwMjr5oRk8l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74f034f3-e38b-4d2b-aabf-85a71886aad2",
        "outputId": "614131d2-54e1-4e7e-9bd9-3d466dff721b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.929\n",
            "Model:                            OLS   Adj. R-squared:                  0.921\n",
            "Method:                 Least Squares   F-statistic:                     116.0\n",
            "Date:                Mon, 18 Nov 2024   Prob (F-statistic):           1.35e-46\n",
            "Time:                        00:58:25   Log-Likelihood:                -142.36\n",
            "No. Observations:                 100   AIC:                             306.7\n",
            "Df Residuals:                      89   BIC:                             335.4\n",
            "Df Model:                          10                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "X              4.1893      0.764      5.484      0.000       2.671       5.707\n",
            "X^2            1.8565      1.681      1.105      0.272      -1.483       5.196\n",
            "X^5            2.5870      3.639      0.711      0.479      -4.644       9.818\n",
            "X^4           -5.5487      2.805     -1.978      0.051     -11.122       0.025\n",
            "X^8           -0.8690      0.580     -1.498      0.138      -2.021       0.283\n",
            "X^7           -0.7925      1.584     -0.500      0.618      -3.939       2.354\n",
            "X^6            3.5792      1.798      1.991      0.050       0.007       7.152\n",
            "X^9            0.0782      0.222      0.352      0.726      -0.363       0.519\n",
            "X^3           -2.8703      3.037     -0.945      0.347      -8.905       3.164\n",
            "X^10           0.0700      0.077      0.905      0.368      -0.084       0.224\n",
            "const          2.0788      0.223      9.314      0.000       1.635       2.522\n",
            "==============================================================================\n",
            "Omnibus:                        2.296   Durbin-Watson:                   2.288\n",
            "Prob(Omnibus):                  0.317   Jarque-Bera (JB):                1.927\n",
            "Skew:                           0.074   Prob(JB):                        0.382\n",
            "Kurtosis:                       3.664   Cond. No.                     8.10e+04\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 8.1e+04. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from itertools import combinations\n",
        "\n",
        "# Prepare dataset with polynomial features\n",
        "data = pd.DataFrame({'X': X})\n",
        "for i in range(2, 11):\n",
        "    data[f'X^{i}'] = X**i\n",
        "\n",
        "# Add intercept\n",
        "data = sm.add_constant(data)\n",
        "\n",
        "# Forward stepwise selection\n",
        "def forward_selection(data, response):\n",
        "    initial_features = []\n",
        "    remaining_features = list(data.columns)\n",
        "    remaining_features.remove('const')\n",
        "    selected_features = []\n",
        "    best_models = []\n",
        "\n",
        "    while remaining_features:\n",
        "        best_model = None\n",
        "        best_cp = np.inf\n",
        "\n",
        "        for feature in remaining_features:\n",
        "            model = sm.OLS(response, data[selected_features + [feature] + ['const']]).fit()\n",
        "            cp = model.aic  # Using AIC as a proxy for Cp\n",
        "\n",
        "            if cp < best_cp:\n",
        "                best_cp = cp\n",
        "                best_model = model\n",
        "                best_feature = feature\n",
        "\n",
        "        selected_features.append(best_feature)\n",
        "        remaining_features.remove(best_feature)\n",
        "        best_models.append(best_model)\n",
        "\n",
        "    return best_models[-1]\n",
        "\n",
        "# Get best model by forward selection\n",
        "best_model_forward = forward_selection(data, Y)\n",
        "print(best_model_forward.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(d)\n",
        "Repeat (c), using backwards stepwise selection. How does your answer compare to the results in (c)?"
      ],
      "metadata": {
        "id": "dWYCw4sQRmZP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4060180-5e68-4c1b-afc3-1b20f4fe736c",
        "outputId": "b0d3741b-b07d-4b72-f6fe-8ffdf3b6c36c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                      -0.000\n",
            "Model:                            OLS   Adj. R-squared:                 -0.000\n",
            "Method:                 Least Squares   F-statistic:                       nan\n",
            "Date:                Mon, 18 Nov 2024   Prob (F-statistic):                nan\n",
            "Time:                        00:58:47   Log-Likelihood:                -274.44\n",
            "No. Observations:                 100   AIC:                             550.9\n",
            "Df Residuals:                      99   BIC:                             553.5\n",
            "Df Model:                           0                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          1.2627      0.378      3.338      0.001       0.512       2.013\n",
            "==============================================================================\n",
            "Omnibus:                       21.467   Durbin-Watson:                   2.100\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               30.002\n",
            "Skew:                          -1.020   Prob(JB):                     3.06e-07\n",
            "Kurtosis:                       4.744   Cond. No.                         1.00\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "def backward_selection(data, response):\n",
        "    remaining_features = list(data.columns)\n",
        "    remaining_features.remove('const')\n",
        "    selected_features = remaining_features[:]\n",
        "    best_models = []\n",
        "\n",
        "    while selected_features:\n",
        "        best_model = None\n",
        "        best_cp = np.inf\n",
        "\n",
        "        for feature in selected_features:\n",
        "            temp_features = selected_features[:]\n",
        "            temp_features.remove(feature)\n",
        "            model = sm.OLS(response, data[temp_features + ['const']]).fit()\n",
        "            cp = model.aic  # Using AIC as a proxy for Cp\n",
        "\n",
        "            if cp < best_cp:\n",
        "                best_cp = cp\n",
        "                best_model = model\n",
        "                removed_feature = feature\n",
        "\n",
        "        if best_model is None:\n",
        "            break\n",
        "\n",
        "        selected_features.remove(removed_feature)\n",
        "        best_models.append(best_model)\n",
        "\n",
        "    return best_models[-1]\n",
        "\n",
        "# Get best model by backward selection\n",
        "best_model_backward = backward_selection(data, Y)\n",
        "print(best_model_backward.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(e)\n",
        "Now fit a lasso model to the simulated data, again using $X,X2, ...,X10$ as predictors. Use cross-validation to select the optimal value of $\\lambda$. Create plots of the cross-validation error as a function of $\\lambda$. Report the resulting coefficient estimates, and discuss the results obtained."
      ],
      "metadata": {
        "id": "JlSNJLtXRmqy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da887f55-8427-46b2-a06c-707f4a1f0966",
        "outputId": "a0eccc0c-67e9-4c9e-aedd-66d878ff2be0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5707570272126077, tolerance: 0.12729885460774923\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.269147055378653, tolerance: 0.12729885460774923\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1421900562125984, tolerance: 0.12729885460774923\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.521497838140931, tolerance: 0.12729885460774923\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4203012855807629, tolerance: 0.12729885460774923\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8921655976400871, tolerance: 0.12729885460774923\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.773792197265152, tolerance: 0.12729885460774923\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.858544570287222, tolerance: 0.12729885460774923\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24.044602785062295, tolerance: 0.12729885460774923\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.148285128775285, tolerance: 0.12729885460774923\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.53423094982924, tolerance: 0.12729885460774923\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.16503750777621917, tolerance: 0.12442036909436252\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.886527236954862, tolerance: 0.12442036909436252\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5132366048979975, tolerance: 0.12442036909436252\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3028610896897135, tolerance: 0.12442036909436252\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.16854099447209592, tolerance: 0.12442036909436252\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.250367002406847, tolerance: 0.12442036909436252\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.90041729756473, tolerance: 0.12442036909436252\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22.53057305294311, tolerance: 0.12442036909436252\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.88422766830655, tolerance: 0.12442036909436252\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.333208106412144, tolerance: 0.12442036909436252\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.062374576645993, tolerance: 0.12442036909436252\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.6554595648967734, tolerance: 0.12912084613690333\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.20642000865473165, tolerance: 0.12912084613690333\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.092638993083483, tolerance: 0.12912084613690333\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5022606048313492, tolerance: 0.12912084613690333\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4653012848821163, tolerance: 0.12912084613690333\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.046631911632744, tolerance: 0.12912084613690333\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.32587255586236097, tolerance: 0.12912084613690333\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.254217701150424, tolerance: 0.12912084613690333\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.906553432426222, tolerance: 0.12912084613690333\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.240492402611153, tolerance: 0.12912084613690333\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.92641853270089, tolerance: 0.12912084613690333\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.24577230834324837, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3740458013312491, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4521294243027114, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5070805756823802, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5470029240063923, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5752330120471925, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5938928582669405, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.604655928919783, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6089245524071885, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6078888053752962, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6025597777440908, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5937951472312761, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5823207385514024, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5687490735904248, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5535953984802973, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5372915321860319, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5201978338246818, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.502613534926013, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.48478565808181884, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.46691670952748154, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4491713086739537, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.43168189898290166, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4633182751435925, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1049343397769462, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0941252428863208, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.236549405868004, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2024007944781943, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.971419345696745, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.937998349059626, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.7303700897080034, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.46785785403398, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.176328032423669, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.8744903539032975, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.575454470532918, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.2880387132201463, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.0178365475395594, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.768065304076913, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5402288344467934, tolerance: 0.12184481801503648\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.13820959084102924, tolerance: 0.12931936549059042\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8304983788522122, tolerance: 0.12931936549059042\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.43179501198733306, tolerance: 0.12931936549059042\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.165788400381416, tolerance: 0.12931936549059042\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3637388280405958, tolerance: 0.12931936549059042\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0799718270950507, tolerance: 0.12931936549059042\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1586839881533706, tolerance: 0.12931936549059042\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.0378166407142544, tolerance: 0.12931936549059042\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.167399390952767, tolerance: 0.12931936549059042\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.95704382972133, tolerance: 0.12931936549059042\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.343185400954894, tolerance: 0.12931936549059042\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.7252550286712, tolerance: 0.12931936549059042\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.7349465227313203, tolerance: 0.12931936549059042\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1978980717808554, tolerance: 0.13667400075329303\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.916223644298384, tolerance: 0.13667400075329303\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.461667047409378, tolerance: 0.13667400075329303\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4273071720243706, tolerance: 0.13667400075329303\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.738162841852045, tolerance: 0.13667400075329303\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.87063967025108, tolerance: 0.13667400075329303\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.733155322618813, tolerance: 0.13667400075329303\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25.881086812394585, tolerance: 0.13667400075329303\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.424050046263346, tolerance: 0.13667400075329303\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.185007300977986, tolerance: 0.13667400075329303\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.640412410528711, tolerance: 0.13667400075329303\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.6219856880612724, tolerance: 0.13667400075329303\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9790762217037354, tolerance: 0.13149174675631747\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8603407759235324, tolerance: 0.13149174675631747\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4507447163442748, tolerance: 0.13149174675631747\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.504849215406125, tolerance: 0.13149174675631747\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0918779512417132, tolerance: 0.13149174675631747\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3053968616173961, tolerance: 0.13149174675631747\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.3784132482385303, tolerance: 0.13149174675631747\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.432651741013956, tolerance: 0.13149174675631747\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.784032094944905, tolerance: 0.13149174675631747\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34.63378969967164, tolerance: 0.13149174675631747\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.357168222143855, tolerance: 0.13149174675631747\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.422922504499184, tolerance: 0.13149174675631747\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15770644240342335, tolerance: 0.13393855702133275\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.137584150266548, tolerance: 0.13393855702133275\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4702291821928384, tolerance: 0.13393855702133275\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2728587792486223, tolerance: 0.13393855702133275\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5409520312981613, tolerance: 0.13393855702133275\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3198449423176726, tolerance: 0.13393855702133275\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6895223473418355, tolerance: 0.13393855702133275\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17713807362281386, tolerance: 0.13393855702133275\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.373478084061844, tolerance: 0.13393855702133275\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21.32196055541465, tolerance: 0.13393855702133275\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.30436405256313, tolerance: 0.13393855702133275\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.32663317389819, tolerance: 0.13393855702133275\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.49316358605074, tolerance: 0.13393855702133275\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2132301115104838, tolerance: 0.1353610741629405\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3213144140544273, tolerance: 0.1353610741629405\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2001385305489976, tolerance: 0.1353610741629405\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5043298151240379, tolerance: 0.1353610741629405\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.285243316051151, tolerance: 0.1353610741629405\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5509154076638652, tolerance: 0.1353610741629405\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.19536746475228, tolerance: 0.1353610741629405\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.854548245796707, tolerance: 0.1353610741629405\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30.774022745800607, tolerance: 0.1353610741629405\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.7586755965209, tolerance: 0.1353610741629405\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.894390122131995, tolerance: 0.1353610741629405\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2086470116279315, tolerance: 0.1353610741629405\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\PINYKEWD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+01, tolerance: 1.417e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lasso = LassoCV(cv=10).fit(X_poly, Y)\n",
        "\n",
        "plt.plot(lasso.alphas_, lasso.mse_path_.mean(axis=1), marker='o')\n",
        "plt.xlabel('Lambda')\n",
        "plt.ylabel('Cross-Validation Error')\n",
        "plt.title('Lasso Cross-Validation Error vs Lambda')\n",
        "plt.xscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(f)\n",
        "Now generate a response vector Y according to the model\n",
        "$$Y = \\beta0+ \\beta_7X^7+\\epsilon,$$\n",
        " and perform forward stepwise selection and the lasso. Discuss\n",
        " the results obtained."
      ],
      "metadata": {
        "id": "gTN9HTO2RnNX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ed3d68a-b998-4339-a23d-2f817a0c2f9c",
        "outputId": "4a92cda2-4fa9-4da2-d52d-c69fdbcdccb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forward Stepwise Selection Coefficients for New Model:\n",
            "[-266.40965923   -3.55208569  -80.63428406   17.4039447   109.94526299\n",
            "   -5.33417907]\n",
            "Lasso Coefficients for New Model:\n",
            "[  0.         104.58588979  -0.          -0.           0.\n",
            " -42.80020607   0.         605.88148804  -0.         131.70834981]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.linear_model import LinearRegression, LassoCV\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X_poly is defined and epsilon is created\n",
        "# Example of how X_poly might look like (X raised to polynomial degrees):\n",
        "X_poly = np.random.randn(100, 10)  # Example feature set\n",
        "beta_0 = 0  # Example intercept\n",
        "beta_7 = 7\n",
        "epsilon = np.random.randn(100)  # Noise term\n",
        "Y_new = beta_0 + beta_7 * X_poly[:, 7]**7 + epsilon  # Adjusted model\n",
        "\n",
        "# Forward stepwise selection for the new model\n",
        "linear_model = LinearRegression()  # Use LinearRegression as the base model for feature selection\n",
        "forward_sfs_new = SequentialFeatureSelector(linear_model, n_features_to_select='auto', direction='forward')\n",
        "forward_sfs_new.fit(X_poly, Y_new)\n",
        "selected_features_forward_new = forward_sfs_new.get_support(indices=True)\n",
        "\n",
        "# Fit the model with selected features\n",
        "X_forward_selected_new = X_poly[:, selected_features_forward_new]\n",
        "model_forward_new = sm.OLS(Y_new, sm.add_constant(X_forward_selected_new)).fit()\n",
        "\n",
        "print(\"Forward Stepwise Selection Coefficients for New Model:\")\n",
        "print(model_forward_new.params)\n",
        "\n",
        "# Lasso for the new model\n",
        "lasso_new = LassoCV(cv=10).fit(X_poly, Y_new)\n",
        "print(\"Lasso Coefficients for New Model:\")\n",
        "print(lasso_new.coef_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a471e72-ee27-4b8d-a7bc-ed552ab742d6"
      },
      "source": [
        "1.Forward Stepwise Selection starts with no variables and adds the most significant variable at each step, so the final model generally includes more non-zero coefficients (as seen here), which may have both positive and negative values.However, it lacks strong regularization, so even small coefficients remain in the model.\n",
        "\n",
        "2.Lasso Regression applies L1 regularization (an absolute value penalty) to perform variable selection by shrinking the coefficients of unimportant variables to zero, resulting in a sparse model that contains only a few significant variables.In this result, only two variables have non-zero coefficients, specifically 1.18509122 and 0.04362939, which means that Lasso identified these as the only variables with substantial predictive value, and it set the other coefficients to zero as they contributed minimally to the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ch6_Q9\n",
        "9. In this exercise, we will predict the number of applications received using the other variables in the College data set."
      ],
      "metadata": {
        "id": "qtthX6aOQT3_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(a)\n",
        "Split the data set into a training set and a test set."
      ],
      "metadata": {
        "id": "Xx21G8n3Qw8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ISLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcA7HuSvQvPJ",
        "outputId": "803cd67f-1e0f-4891-9537-4e7f52a21c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ISLP\n",
            "  Downloading ISLP-0.4.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.13.1)\n",
            "Requirement already satisfied: pandas>=0.20 in /usr/local/lib/python3.10/dist-packages (from ISLP) (2.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from ISLP) (5.3.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.5.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.4.2)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from ISLP) (0.14.4)\n",
            "Collecting lifelines (from ISLP)\n",
            "  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pygam (from ISLP)\n",
            "  Downloading pygam-0.9.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ISLP) (2.5.1+cu121)\n",
            "Collecting pytorch-lightning (from ISLP)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchmetrics (from ISLP)\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20->ISLP) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20->ISLP) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20->ISLP) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2->ISLP) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->ISLP) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->ISLP) (24.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines->ISLP) (3.8.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines->ISLP) (1.7.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines->ISLP)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines->ISLP)\n",
            "  Downloading formulaic-1.0.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: progressbar2<5.0.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pygam->ISLP) (4.5.0)\n",
            "Collecting scipy>=0.9 (from ISLP)\n",
            "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->ISLP) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->ISLP) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->ISLP) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning->ISLP)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->ISLP) (1.3.0)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines->ISLP)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning->ISLP) (75.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (3.2.0)\n",
            "Requirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from progressbar2<5.0.0,>=4.2.0->pygam->ISLP) (3.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.20->ISLP) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ISLP) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.10)\n",
            "Downloading ISLP-0.4.0-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygam-0.9.1-py3-none-any.whl (522 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m522.0/522.0 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.0.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=147d901d8bb5a349cf98939940058a4897d9713ea83ee3823475a3d0b6554ce3\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/cc/e0/ef2969164144c899fedb22b338f6703e2b9cf46eeebf254991\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: scipy, lightning-utilities, interface-meta, autograd-gamma, torchmetrics, pygam, formulaic, lifelines, pytorch-lightning, ISLP\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "Successfully installed ISLP-0.4.0 autograd-gamma-0.5.0 formulaic-1.0.2 interface-meta-1.3.0 lifelines-0.30.0 lightning-utilities-0.11.9 pygam-0.9.1 pytorch-lightning-2.4.0 scipy-1.11.4 torchmetrics-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ISLP import load_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the College dataset\n",
        "college = load_data('College')\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = college.drop(\"Apps\", axis=1)\n",
        "y = college[\"Apps\"]\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "# Split the dataset into a training set and a test set (80% training, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "PRO6Kbv_T1gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Test set shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djd9fLr3UH1G",
        "outputId": "59abc485-6022-4395-a04d-64075feac197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (621, 17)\n",
            "Test set shape: (156, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(b)\n",
        "Fit a linear model using least squares on the training set, and report the test error obtained."
      ],
      "metadata": {
        "id": "Idb5Y7oDQyLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Initialize and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the test error (mean squared error)\n",
        "test_error = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Test Error (MSE): {test_error}\")"
      ],
      "metadata": {
        "id": "uYMZ9pMGQ1DH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c4bd43-76a1-4bb9-babd-f44bc164f8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error (MSE): 1492443.379039042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(c)\n",
        "Fit a ridge regression model on the training set, with λ chosen by cross-validation. Report the test error obtained."
      ],
      "metadata": {
        "id": "iOMWXyUmQ373"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RidgeCV\n",
        "\n",
        "# Initialize and fit the ridge regression model with cross-validation\n",
        "alphas = [0.1, 1, 10, 100, 1000]  # Example alpha values for cross-validation\n",
        "ridge_cv_model = RidgeCV(alphas=alphas, cv=5) # Use 5-fold cross-validation\n",
        "ridge_cv_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set using the best lambda\n",
        "y_pred_ridge_cv = ridge_cv_model.predict(X_test)\n",
        "\n",
        "# Calculate the test error (mean squared error) for the ridge regression model\n",
        "test_error_ridge_cv = mean_squared_error(y_test, y_pred_ridge_cv)\n",
        "print(f\"Test Error (Ridge CV, MSE): {test_error_ridge_cv}\")\n",
        "print(f\"Best alpha (lambda): {ridge_cv_model.alpha_}\")"
      ],
      "metadata": {
        "id": "jhXL1Q9sQ375",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe95944-800a-4e43-84f9-41e0da66953f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error (Ridge CV, MSE): 1478572.8112797008\n",
            "Best alpha (lambda): 10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(d)\n",
        "Fit a lasso model on the training set, with λ chosen by cross- validation. Report the test error obtained, along with the num- ber of non-zero coefficient estimates."
      ],
      "metadata": {
        "id": "4zEDLbmXQ4DL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "# Initialize and fit the lasso model with cross-validation\n",
        "lasso_cv_model = LassoCV(alphas=alphas, cv=5)  # Use 5-fold cross-validation\n",
        "lasso_cv_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set using the best lambda\n",
        "y_pred_lasso_cv = lasso_cv_model.predict(X_test)\n",
        "\n",
        "# Calculate the test error (mean squared error) for the lasso model\n",
        "test_error_lasso_cv = mean_squared_error(y_test, y_pred_lasso_cv)\n",
        "print(f\"Test Error (Lasso CV, MSE): {test_error_lasso_cv}\")\n",
        "print(f\"Best alpha (lambda): {lasso_cv_model.alpha_}\")\n",
        "\n",
        "# Count the number of non-zero coefficients\n",
        "non_zero_coefs = sum(lasso_cv_model.coef_ != 0)\n",
        "print(f\"Number of non-zero coefficients: {non_zero_coefs}\")"
      ],
      "metadata": {
        "id": "KySCXWPuQ4DM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ff9e3f-42ce-4dac-d84e-29c336038501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error (Lasso CV, MSE): 1477248.9589983297\n",
            "Best alpha (lambda): 10.0\n",
            "Number of non-zero coefficients: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(e)\n",
        "Fit a PCR model on the training set, with M chosen by cross- validation. Report the test error obtained, along with the value of M selected by cross-validation."
      ],
      "metadata": {
        "id": "FyCleYvRQ4GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# PCR model with cross-validation\n",
        "best_test_error = float('inf')\n",
        "best_M = 0\n",
        "\n",
        "for M in range(1, X_train.shape[1] + 1):\n",
        "    pca = PCA(n_components=M)\n",
        "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "    X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "    pcr_model = LinearRegression()\n",
        "    pcr_model.fit(X_train_pca, y_train)\n",
        "\n",
        "    y_pred_pcr = pcr_model.predict(X_test_pca)\n",
        "    test_error_pcr = mean_squared_error(y_test, y_pred_pcr)\n",
        "\n",
        "    if test_error_pcr < best_test_error:\n",
        "        best_test_error = test_error_pcr\n",
        "        best_M = M\n",
        "\n",
        "print(f\"Test Error (PCR CV, MSE): {best_test_error}\")\n",
        "print(f\"Best M (Number of Principal Components): {best_M}\")\n"
      ],
      "metadata": {
        "id": "mW0MIaUZQ4GO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab7e2fd-7912-43b2-cd67-07a7994e8e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error (PCR CV, MSE): 1492443.3790390224\n",
            "Best M (Number of Principal Components): 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(f)\n",
        "Fit a PLS model on the training set, with M chosen by cross- validation. Report the test error obtained, along with the value of M selected by cross-validation."
      ],
      "metadata": {
        "id": "pvMSlTiMQ4I0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cross_decomposition import PLSRegression\n",
        "\n",
        "# PLS model with cross-validation\n",
        "best_test_error_pls = float('inf')\n",
        "best_M_pls = 0\n",
        "\n",
        "for M in range(1, min(X_train.shape[1], X_train.shape[0]) + 1):\n",
        "    pls_model = PLSRegression(n_components=M)\n",
        "    pls_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    y_pred_pls = pls_model.predict(X_test_scaled)\n",
        "    test_error_pls = mean_squared_error(y_test, y_pred_pls)\n",
        "\n",
        "    if test_error_pls < best_test_error_pls:\n",
        "        best_test_error_pls = test_error_pls\n",
        "        best_M_pls = M\n",
        "\n",
        "print(f\"Test Error (PLS CV, MSE): {best_test_error_pls}\")\n",
        "print(f\"Best M (Number of PLS components): {best_M_pls}\")"
      ],
      "metadata": {
        "id": "MQMxa0ETQ4I1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a88dcb0-b4dc-47a9-81d4-4c9f679e5355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error (PLS CV, MSE): 1448566.3424517359\n",
            "Best M (Number of PLS components): 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(g)\n",
        "Comment on the results obtained. How accurately can we pre- dict the number of college applications received? Is there much difference among the test errors resulting from these five ap- proaches?"
      ],
      "metadata": {
        "id": "3Kgc7_ZgRaVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of College Applications Prediction:\n",
        "\n",
        "Based on the results, the prediction accuracy of college applications varies among the models tested.  The MSE values provide a measure of the error, with lower values indicating better performance.\n",
        "While the test errors are relatively close for several of these methods, there's no single 'best' approach.\n",
        "\n",
        "Further considerations:\n",
        "1. Magnitude of Error:\n",
        "Evaluate the absolute values of the MSEs in relation to the range of applications received.  A small MSE might still represent a substantial error if applications vary greatly.\n",
        "\n",
        "2. Model Interpretability:\n",
        "The simple linear regression provides easy-to-understand coefficients. Ridge and Lasso introduce regularization which can improve predictions but might reduce interpretability. PCR and PLS offer dimensionality reduction and could reveal underlying factors driving applications, but the resulting models can be more difficult to interpret.\n",
        "\n",
        "3. Feature Importance:\n",
        "The non-zero coefficients in the Lasso model highlight important features affecting applications.\n",
        "\n",
        "4. Cross-Validation Tuning:\n",
        "The choice of optimal hyperparameters (alpha for ridge/lasso, M for PCR/PLS) through cross-validation is crucial. Different hyperparameter ranges could lead to different optimal values and potentially better performance.  It's important to note that the provided code only tries a few alphas.\n",
        "\n",
        "5. Model Comparison:\n",
        "The differences observed in test errors might not be statistically significant. Consider using statistical tests (e.g. F-tests or paired t-tests) to ascertain if differences are meaningful.\n",
        "\n",
        "Overall:\n",
        "It's likely that no single model is definitively superior.  The choice of model depends on the desired balance between prediction accuracy and interpretability."
      ],
      "metadata": {
        "id": "9Ok4SpahncjU"
      }
    }
  ]
}