{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "9. We will now consider the Boston housing data set, from the ISLP\n",
        "library."
      ],
      "metadata": {
        "id": "bAvRUF5Z8wG4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41qkDwN78nKa",
        "outputId": "c5b2b6dc-b47f-469a-ba3f-f89dc1d22a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ISLP\n",
            "  Downloading ISLP-0.4.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.13.1)\n",
            "Requirement already satisfied: pandas>=0.20 in /usr/local/lib/python3.10/dist-packages (from ISLP) (2.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from ISLP) (5.3.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.5.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.4.2)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from ISLP) (0.14.4)\n",
            "Collecting lifelines (from ISLP)\n",
            "  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pygam (from ISLP)\n",
            "  Downloading pygam-0.9.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ISLP) (2.5.0+cu121)\n",
            "Collecting pytorch-lightning (from ISLP)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchmetrics (from ISLP)\n",
            "  Downloading torchmetrics-1.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20->ISLP) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20->ISLP) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20->ISLP) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2->ISLP) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->ISLP) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->ISLP) (24.1)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines->ISLP) (3.8.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines->ISLP) (1.7.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines->ISLP)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines->ISLP)\n",
            "  Downloading formulaic-1.0.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: progressbar2<5.0.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pygam->ISLP) (4.5.0)\n",
            "Collecting scipy>=0.9 (from ISLP)\n",
            "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->ISLP) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->ISLP) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->ISLP) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning->ISLP)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->ISLP) (1.3.0)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines->ISLP)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.10.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning->ISLP) (75.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (3.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.13->ISLP) (1.16.0)\n",
            "Requirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from progressbar2<5.0.0,>=4.2.0->pygam->ISLP) (3.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ISLP) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (0.2.0)\n",
            "Downloading ISLP-0.4.0-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygam-0.9.1-py3-none-any.whl (522 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m522.0/522.0 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.5.1-py3-none-any.whl (890 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.6/890.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.0.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=ae4752c6e64f431772a162387e1a2994596f3759a78d4aa61945e81e7d94ba94\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/cc/e0/ef2969164144c899fedb22b338f6703e2b9cf46eeebf254991\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: scipy, lightning-utilities, interface-meta, autograd-gamma, torchmetrics, pygam, formulaic, lifelines, pytorch-lightning, ISLP\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "Successfully installed ISLP-0.4.0 autograd-gamma-0.5.0 formulaic-1.0.2 interface-meta-1.3.0 lifelines-0.30.0 lightning-utilities-0.11.8 pygam-0.9.1 pytorch-lightning-2.4.0 scipy-1.11.4 torchmetrics-1.5.1\n"
          ]
        }
      ],
      "source": [
        "# Install the ISLP library if it's not already installed\n",
        "!pip install ISLP\n",
        "\n",
        "# Import necessary libraries\n",
        "import ISLP\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Boston housing dataset\n",
        "boston = ISLP.load_data('Boston')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) Based on this data set, provide an estimate for the population\n",
        "mean of medv. Call this estimate $\\hat{\\mu}$."
      ],
      "metadata": {
        "id": "iRr0EAqL88P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu_hat = boston['medv'].mean()\n",
        "print(f\"The estimate for the population mean of medv (mu_hat) is: {mu_hat}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfm2M56Y9XCy",
        "outputId": "d5d70f71-d7e5-43ea-caa6-ebcaaa3ae13c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimate for the population mean of medv (mu_hat) is: 22.532806324110677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Provide an estimate of the standard error of $\\hat{\\mu}$. Interpret this\n",
        "result.\n",
        "\n",
        "Hint: We can compute the standard error of the sample mean by\n",
        "dividing the sample standard deviation by the square root of the\n",
        "number of observations."
      ],
      "metadata": {
        "id": "-hBWqPao9gwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate the standard error of mu_hat\n",
        "standard_error = boston['medv'].std() / np.sqrt(len(boston))\n",
        "\n",
        "print(f\"The estimated standard error of mu_hat is: {standard_error}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTKEdBNF9pty",
        "outputId": "d70fe7f0-5045-4217-af3f-a0aa47212e92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated standard error of mu_hat is: 0.4088611474975351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "The standard error of $\\hat{\\mu}$ represents the estimated variability\n",
        "or uncertainty in our sample mean ($\\hat{\\mu}$) as an estimate of the\n",
        "true population mean of medv.  \n",
        "A smaller standard error suggests that our estimate of the\n",
        "population mean is likely more precise.\n",
        "In this case, the standard error is relatively small, indicating that\n",
        "our estimate of the population mean ($\\hat{\\mu}$) is likely a good\n",
        "representation of the true population mean."
      ],
      "metadata": {
        "id": "NPoV2K4Q-QZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Now estimate the standard error of $\\hat{\\mu}$ using the bootstrap. How\n",
        "does this compare to your answer from (b)?"
      ],
      "metadata": {
        "id": "sf47nzgV-ajf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of bootstrap samples\n",
        "n_bootstrap = 1000\n",
        "\n",
        "# Initialize an array to store the bootstrap sample means\n",
        "bootstrap_means = np.empty(n_bootstrap)\n",
        "\n",
        "# Perform bootstrapping\n",
        "for i in range(n_bootstrap):\n",
        "    # Sample with replacement from the original data\n",
        "    bootstrap_sample = boston['medv'].sample(n=len(boston), replace=True)\n",
        "    # Calculate the mean of the bootstrap sample\n",
        "    bootstrap_means[i] = bootstrap_sample.mean()\n",
        "\n",
        "# Estimate the standard error of mu_hat using the bootstrap\n",
        "bootstrap_standard_error = np.std(bootstrap_means)\n",
        "\n",
        "print(f\"The estimated standard error of mu_hat using the bootstrap is: {bootstrap_standard_error}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpUQPqMd-ijI",
        "outputId": "fe53c3b3-3ed6-4062-ccd3-a5671f93312d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated standard error of mu_hat using the bootstrap is: 0.4130365394388512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison:\n",
        "The bootstrap estimate of the standard error is likely to be more accurate,\n",
        "especially when the data does not follow a normal distribution.\n",
        "Comparing the bootstrap standard error to the standard error from (b), we see\n",
        "that the two values are relatively similar. This suggests that the standard\n",
        "error calculated using the sample standard deviation and the square root of\n",
        "the number of observations is a decent approximation in this case."
      ],
      "metadata": {
        "id": "1oYdljKD-zY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) Based on your bootstrap estimate from (c), provide a 95 % confidence\n",
        "interval for the mean of medv. Compare it to the results\n",
        "obtained by using Boston['medv'].std() and the two standard\n",
        "error rule (3.9).\n",
        "\n",
        "Hint: You can approximate a 95 % confidence interval using the\n",
        "formula [ˆμ − 2SE(ˆμ), ˆμ + 2SE(ˆμ)]."
      ],
      "metadata": {
        "id": "F4Q_OANY_DGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the 95% confidence interval using the bootstrap standard error\n",
        "confidence_interval_bootstrap = [mu_hat - 2 * bootstrap_standard_error, mu_hat + 2 * bootstrap_standard_error]\n",
        "\n",
        "print(f\"The 95% confidence interval for the mean of medv (using bootstrap) is: {confidence_interval_bootstrap}\")\n",
        "\n",
        "\n",
        "# Calculate the 95% confidence interval using Boston['medv'].std() and the two standard error rule\n",
        "confidence_interval_standard_error = [mu_hat - 2 * standard_error, mu_hat + 2 * standard_error]\n",
        "\n",
        "print(f\"The 95% confidence interval for the mean of medv (using standard error) is: {confidence_interval_standard_error}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwT1hmAp_H4y",
        "outputId": "cd4d3447-abd4-4f5a-ccc1-5810bfc7f795"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 95% confidence interval for the mean of medv (using bootstrap) is: [21.706733245232975, 23.35887940298838]\n",
            "The 95% confidence interval for the mean of medv (using standard error) is: [21.715084029115605, 23.35052861910575]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confidence intervals obtained using the bootstrap and the standard error are\n",
        "quite similar. This indicates that the standard error calculated using the\n",
        "sample standard deviation provides a reasonable approximation for the\n",
        "standard error of the sample mean in this case."
      ],
      "metadata": {
        "id": "OTqNQsut_bCg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(e) Based on this data set, provide an estimate, $\\hat{\\mu}_{med}$, for the median\n",
        "value of medv in the population."
      ],
      "metadata": {
        "id": "XLC4x87m_iz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu_med_hat = boston['medv'].median()\n",
        "\n",
        "print(f\"The estimate for the population median of medv (mu_med_hat) is: {mu_med_hat}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfHNolLD_4hK",
        "outputId": "d12c56f8-5e88-4e07-984a-c69e9c15e7f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimate for the population median of medv (mu_med_hat) is: 21.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(f) We now would like to estimate the standard error of $\\hat{\\mu}_{med}$. Unfortunately,\n",
        "there is no simple formula for computing the standard\n",
        "error of the median. Instead, estimate the standard error of the\n",
        "median using the bootstrap. Comment on your findings."
      ],
      "metadata": {
        "id": "3AOq6SBzACKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of bootstrap samples\n",
        "n_bootstrap = 1000\n",
        "\n",
        "# Initialize an array to store the bootstrap sample medians\n",
        "bootstrap_medians = np.empty(n_bootstrap)\n",
        "\n",
        "# Perform bootstrapping\n",
        "for i in range(n_bootstrap):\n",
        "    # Sample with replacement from the original data\n",
        "    bootstrap_sample = boston['medv'].sample(n=len(boston), replace=True)\n",
        "    # Calculate the median of the bootstrap sample\n",
        "    bootstrap_medians[i] = bootstrap_sample.median()\n",
        "\n",
        "# Estimate the standard error of mu_med_hat using the bootstrap\n",
        "bootstrap_standard_error_median = np.std(bootstrap_medians)\n",
        "\n",
        "print(f\"The estimated standard error of mu_med_hat using the bootstrap is: {bootstrap_standard_error_median}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iuiOlPGALmS",
        "outputId": "311982b6-8d59-4af2-e70a-cbfe165da622"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated standard error of mu_med_hat using the bootstrap is: 0.38131246701360255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing the standard error of the mean (from previous parts) and the standard error of the median (current),\n",
        "we can observe that the standard error of the mean is typically smaller than that of the median.\n",
        "This is because the mean is generally more robust and less affected by outliers than the median."
      ],
      "metadata": {
        "id": "mFp-Z0gcAViw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(g) Based on this data set, provide an estimate for the tenth percentile\n",
        "of medv in Boston census tracts.\n",
        "\n",
        "Call this quantity $\\hat{\\mu}_{0.1}$.\n",
        "(You can use the np.percentile() function.)\n",
        "\n"
      ],
      "metadata": {
        "id": "Xvkkhwe0A7nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu_01_hat = np.percentile(boston['medv'], 10)\n",
        "\n",
        "print(f\"The estimate for the tenth percentile of medv (mu_0.1_hat) is: {mu_01_hat}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DpeHAe4BLtu",
        "outputId": "08b75b53-de2b-471d-a212-8d433dda1209"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimate for the tenth percentile of medv (mu_0.1_hat) is: 12.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(h) Use the bootstrap to estimate the standard error of $\\hat{\\mu}_{0.1}$. Comment\n",
        "on your findings."
      ],
      "metadata": {
        "id": "8pqj7djEBfd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of bootstrap samples\n",
        "n_bootstrap = 1000\n",
        "\n",
        "# Initialize an array to store the bootstrap sample 10th percentiles\n",
        "bootstrap_percentiles_01 = np.empty(n_bootstrap)\n",
        "\n",
        "# Perform bootstrapping\n",
        "for i in range(n_bootstrap):\n",
        "    # Sample with replacement from the original data\n",
        "    bootstrap_sample = boston['medv'].sample(n=len(boston), replace=True)\n",
        "    # Calculate the 10th percentile of the bootstrap sample\n",
        "    bootstrap_percentiles_01[i] = np.percentile(bootstrap_sample, 10)\n",
        "\n",
        "# Estimate the standard error of mu_0.1_hat using the bootstrap\n",
        "bootstrap_standard_error_percentile_01 = np.std(bootstrap_percentiles_01)\n",
        "\n",
        "print(f\"The estimated standard error of mu_0.1_hat using the bootstrap is: {bootstrap_standard_error_percentile_01}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXllbDC3BmMj",
        "outputId": "db879989-3be6-426c-e5b3-4d830a05d9ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated standard error of mu_0.1_hat using the bootstrap is: 0.5065491067014134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment on findings:\n",
        "The bootstrap estimate of the standard error of the 10th percentile provides\n",
        "an indication of the uncertainty in our estimate of the 10th percentile\n",
        "of medv.  A smaller standard error suggests that our estimate is more\n",
        "precise.\n",
        "In general, the standard error of a percentile is typically larger than\n",
        "that of the mean or median, as percentiles are more sensitive to\n",
        "the extreme values in the data.\n",
        "In this case, the bootstrap standard error of the 10th percentile is relatively\n",
        "small, indicating that our estimate of the 10th percentile is likely\n",
        "fairly precise."
      ],
      "metadata": {
        "id": "f3WeDnXJBvUQ"
      }
    }
  ]
}