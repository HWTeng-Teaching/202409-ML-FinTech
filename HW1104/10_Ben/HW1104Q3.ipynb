{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ch05_Q09\n",
        "\n",
        "9. We will now consider the Boston housing data set, from the ISLP\n",
        "library.\n",
        "\n",
        "(a) Based on this data set, provide an estimate for the population\n",
        "mean of medv. Call this estimate ˆμ."
      ],
      "metadata": {
        "id": "YGV6XQs1HTUl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTnIRDyZHNm0",
        "outputId": "602f3f2b-4607-47d7-e3f4-1b3ee4a456b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ISLP\n",
            "  Downloading ISLP-0.4.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.13.1)\n",
            "Requirement already satisfied: pandas>=0.20 in /usr/local/lib/python3.10/dist-packages (from ISLP) (2.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from ISLP) (5.3.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.5.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.4.2)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from ISLP) (0.14.4)\n",
            "Collecting lifelines (from ISLP)\n",
            "  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pygam (from ISLP)\n",
            "  Downloading pygam-0.9.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ISLP) (2.5.0+cu121)\n",
            "Collecting pytorch-lightning (from ISLP)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchmetrics (from ISLP)\n",
            "  Downloading torchmetrics-1.5.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20->ISLP) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20->ISLP) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20->ISLP) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2->ISLP) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->ISLP) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->ISLP) (24.1)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines->ISLP) (3.8.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines->ISLP) (1.7.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines->ISLP)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines->ISLP)\n",
            "  Downloading formulaic-1.0.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: progressbar2<5.0.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pygam->ISLP) (4.5.0)\n",
            "Collecting scipy>=0.9 (from ISLP)\n",
            "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->ISLP) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->ISLP) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->ISLP) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning->ISLP)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->ISLP) (1.3.0)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines->ISLP)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.10.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning->ISLP) (75.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (3.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.13->ISLP) (1.16.0)\n",
            "Requirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from progressbar2<5.0.0,>=4.2.0->pygam->ISLP) (3.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ISLP) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (0.2.0)\n",
            "Downloading ISLP-0.4.0-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygam-0.9.1-py3-none-any.whl (522 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m522.0/522.0 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.5.2-py3-none-any.whl (891 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.4/891.4 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.0.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=aa8c6a4f46cc0ad8e98e2f984286503f98c30ec1397a9a6f6ecde417c0326499\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/cc/e0/ef2969164144c899fedb22b338f6703e2b9cf46eeebf254991\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: scipy, lightning-utilities, interface-meta, autograd-gamma, torchmetrics, pygam, formulaic, lifelines, pytorch-lightning, ISLP\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "Successfully installed ISLP-0.4.0 autograd-gamma-0.5.0 formulaic-1.0.2 interface-meta-1.3.0 lifelines-0.30.0 lightning-utilities-0.11.8 pygam-0.9.1 pytorch-lightning-2.4.0 scipy-1.11.4 torchmetrics-1.5.2\n"
          ]
        }
      ],
      "source": [
        "# Install the ISLP library\n",
        "!pip install ISLP\n",
        "\n",
        "# Import necessary libraries\n",
        "import ISLP\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Boston housing dataset\n",
        "boston = ISLP.load_data('Boston')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the estimate of the population mean for 'medv'\n",
        "mu_hat = boston['medv'].mean()\n",
        "\n",
        "# Print the result\n",
        "print(f\"The estimated population mean (mu_hat) of 'medv' is: {mu_hat}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYGn9wcDKixl",
        "outputId": "f6b65a1c-dfd4-4739-baf8-e861e7f8b11f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated population mean (mu_hat) of 'medv' is: 22.532806324110677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Provide an estimate of the standard error of ˆμ. Interpret this\n",
        "result.\n",
        "\n",
        "Hint: We can compute the standard error of the sample mean by\n",
        "dividing the sample standard deviation by the square root of the\n",
        "number of observations."
      ],
      "metadata": {
        "id": "10kKx4UnKpBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate the sample mean of 'medv'\n",
        "mu_hat = boston['medv'].mean()\n",
        "\n",
        "# Calculate the sample standard deviation of 'medv'\n",
        "std_dev = boston['medv'].std()\n",
        "\n",
        "# Calculate the number of observations\n",
        "n = len(boston['medv'])\n",
        "\n",
        "# Calculate the standard error of mu_hat\n",
        "se_mu_hat = std_dev / np.sqrt(n)\n",
        "\n",
        "# Print the result\n",
        "print(f\"The estimated standard error of mu_hat is: {se_mu_hat}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVDHQHNDKs13",
        "outputId": "2ba4e7e4-0857-40d5-a67a-fd277795a81e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated standard error of mu_hat is: 0.4088611474975351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Now estimate the standard error of ˆμ using the bootstrap. How\n",
        "does this compare to your answer from (b)?"
      ],
      "metadata": {
        "id": "rVDC-PYpLtPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "np.random.seed(0)  # Set seed for reproducibility\n",
        "\n",
        "# Define bootstrap parameters\n",
        "n_bootstrap_samples = 1000  # Number of bootstrap samples\n",
        "bootstrap_means = []\n",
        "\n",
        "# Perform bootstrap sampling\n",
        "for _ in range(n_bootstrap_samples):\n",
        "    # Create a bootstrap sample by sampling with replacement\n",
        "    bootstrap_sample = boston['medv'].sample(n=len(boston['medv']), replace=True)\n",
        "    # Calculate the mean of the bootstrap sample and store it\n",
        "    bootstrap_means.append(bootstrap_sample.mean())\n",
        "\n",
        "# Calculate the standard error as the standard deviation of the bootstrap means\n",
        "bootstrap_se_mu_hat = np.std(bootstrap_means)\n",
        "\n",
        "# Print the result\n",
        "print(f\"The bootstrap estimate of the standard error of mu_hat is: {bootstrap_se_mu_hat}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkkxh8RCLtpv",
        "outputId": "eab5cc49-0a70-450a-bef5-28afb2041116"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The bootstrap estimate of the standard error of mu_hat is: 0.41163337514478704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison with Part (b), the bootstrap standard error provides an empirical estimate based on resampling, which might differ slightly from the theoretical calculation in part (b). The bootstrap approach does not rely on assumptions about the distribution of medv, making it a useful alternative in cases where the distribution might not be normal or when the sample size is small."
      ],
      "metadata": {
        "id": "D6kLC516L1WG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) Based on your bootstrap estimate from (c), provide a 95 % confidence\n",
        "interval for the mean of medv. Compare it to the results\n",
        "obtained by using Boston['medv'].std() and the two standard\n",
        "error rule (3.9)."
      ],
      "metadata": {
        "id": "sxiNgR5OL91b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the sample mean of 'medv'\n",
        "mu_hat = boston['medv'].mean()\n",
        "\n",
        "# Calculate the 95% confidence interval using the bootstrap standard error\n",
        "ci_lower_bootstrap = mu_hat - 2 * bootstrap_se_mu_hat\n",
        "ci_upper_bootstrap = mu_hat + 2 * bootstrap_se_mu_hat\n",
        "\n",
        "# Print the bootstrap-based confidence interval\n",
        "print(f\"Bootstrap 95% confidence interval for the mean of 'medv': ({ci_lower_bootstrap}, {ci_upper_bootstrap})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEy5dwjfL3Fv",
        "outputId": "ff3d8185-0fd0-4951-fbe1-526c63313ee4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrap 95% confidence interval for the mean of 'medv': (21.709539573821104, 23.35607307440025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the 95% confidence interval using the theoretical standard error from part (b)\n",
        "ci_lower_theoretical = mu_hat - 2 * se_mu_hat\n",
        "ci_upper_theoretical = mu_hat + 2 * se_mu_hat\n",
        "\n",
        "# Print the theoretical confidence interval\n",
        "print(f\"Theoretical 95% confidence interval for the mean of 'medv' using two standard errors: ({ci_lower_theoretical}, {ci_upper_theoretical})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNPBvbUqM48M",
        "outputId": "a3087256-6c34-45e7-fa1a-69254b1e311d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theoretical 95% confidence interval for the mean of 'medv' using two standard errors: (21.715084029115605, 23.35052861910575)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bootstrap confidence interval may differ slightly from the one calculated using the theoretical standard error. This difference can provide insight into whether the theoretical assumptions hold well for this dataset. If the intervals are similar, it suggests that the theoretical approach provides a reasonable approximation; if they differ significantly, the bootstrap might give a more accurate empirical estimate."
      ],
      "metadata": {
        "id": "ABdUF4wfNBzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(e) Based on this data set, provide an estimate, ˆμmed, for the median\n",
        "value of medv in the population."
      ],
      "metadata": {
        "id": "d_S845DwNPQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the estimate for the median of 'medv'\n",
        "mu_med_hat = boston['medv'].median()\n",
        "\n",
        "# Print the result\n",
        "print(f\"The estimated population median (mu_med_hat) of 'medv' is: {mu_med_hat}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1pOpjYNNCMu",
        "outputId": "e1fa9d10-f5fc-4df1-c215-6cd20c7a1f6a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated population median (mu_med_hat) of 'medv' is: 21.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(f) We now would like to estimate the standard error of ˆμmed. Unfortunately,\n",
        "there is no simple formula for computing the standard\n",
        "error of the median. Instead, estimate the standard error of the\n",
        "median using the bootstrap. Comment on your findings."
      ],
      "metadata": {
        "id": "zBla90emObMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Define bootstrap parameters\n",
        "n_bootstrap_samples = 1000  # Number of bootstrap samples\n",
        "bootstrap_medians = []\n",
        "\n",
        "# Perform bootstrap sampling\n",
        "for _ in range(n_bootstrap_samples):\n",
        "    # Create a bootstrap sample by sampling with replacement\n",
        "    bootstrap_sample = boston['medv'].sample(n=len(boston['medv']), replace=True)\n",
        "    # Calculate the median of the bootstrap sample and store it\n",
        "    bootstrap_medians.append(bootstrap_sample.median())\n",
        "\n",
        "# Calculate the standard error as the standard deviation of the bootstrap medians\n",
        "bootstrap_se_mu_med = np.std(bootstrap_medians)\n",
        "\n",
        "# Print the result\n",
        "print(f\"The bootstrap estimate of the standard error of the median (mu_med_hat) is: {bootstrap_se_mu_med}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bow9u7AbObgP",
        "outputId": "7ef913c6-d17d-421f-8eef-a4d19dbf75bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The bootstrap estimate of the standard error of the median (mu_med_hat) is: 0.3950537147021905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bootstrap estimate of the standard error of the median provides an empirical measure of how much the median would vary if we were to repeatedly sample from the population. Since there is no simple formula for the standard error of the median, the bootstrap approach is a practical way to estimate this value.\n",
        "\n",
        "The standard error obtained through the bootstrap might be larger than the standard error of the mean because the median is generally less affected by extreme values than the mean, making it a more robust measure but with potentially higher variability across samples."
      ],
      "metadata": {
        "id": "UfbITeQXOgSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(g) Based on this data set, provide an estimate for the tenth percentile\n",
        "of medv in Boston census tracts. Call this quantity ˆμ0.1.\n",
        "(You can use the np.percentile() function.)"
      ],
      "metadata": {
        "id": "IGyeaATjOjYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the 10th percentile of 'medv'\n",
        "mu_0_1_hat = np.percentile(boston['medv'], 10)\n",
        "\n",
        "# Print the result\n",
        "print(f\"The estimated tenth percentile (mu_0.1_hat) of 'medv' is: {mu_0_1_hat}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMEUL55OOdnf",
        "outputId": "b1a90b5a-01b8-4d46-920d-46b868b331c6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated tenth percentile (mu_0.1_hat) of 'medv' is: 12.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(h) Use the bootstrap to estimate the standard error of μˆ0.1 percentile() . Comment\n",
        "on your findings."
      ],
      "metadata": {
        "id": "y5towPJeOpjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Define bootstrap parameters\n",
        "n_bootstrap_samples = 1000  # Number of bootstrap samples\n",
        "bootstrap_percentiles = []\n",
        "\n",
        "# Perform bootstrap sampling\n",
        "for _ in range(n_bootstrap_samples):\n",
        "    # Create a bootstrap sample by sampling with replacement\n",
        "    bootstrap_sample = boston['medv'].sample(n=len(boston['medv']), replace=True)\n",
        "    # Calculate the 10th percentile of the bootstrap sample and store it\n",
        "    bootstrap_percentiles.append(np.percentile(bootstrap_sample, 10))\n",
        "\n",
        "# Calculate the standard error as the standard deviation of the bootstrap percentiles\n",
        "bootstrap_se_mu_0_1 = np.std(bootstrap_percentiles)\n",
        "\n",
        "# Print the result\n",
        "print(f\"The bootstrap estimate of the standard error of the 10th percentile (mu_0.1_hat) is: {bootstrap_se_mu_0_1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYP3ibZKOmi-",
        "outputId": "38b0db6d-9ddf-40e4-d8b4-0f27b55ec159"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The bootstrap estimate of the standard error of the 10th percentile (mu_0.1_hat) is: 0.49966926811642115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The standard error of the 10th percentile provides a measure of the variability in the 10th percentile estimate across different samples. Since percentiles are less sensitive to extreme values than the mean, we would generally expect the standard error for percentiles to be smaller than that of the mean, but this can depend on the data distribution.\n",
        "\n",
        "The bootstrap approach is particularly useful for estimating the standard error of percentiles, as there is no simple formula for it. By resampling and computing the percentiles from the bootstrap samples, we obtain a more empirical estimate of the variability of the 10th percentile across repeated samples from the population."
      ],
      "metadata": {
        "id": "j2I5tdpIO5Ac"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U54aiO6xO5lW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}