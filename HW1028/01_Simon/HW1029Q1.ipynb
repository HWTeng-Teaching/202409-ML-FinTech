{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This question should be answered using the Weekly data set, which\n",
        "is part of the ISLP package. This data is similar in nature to the\n",
        "Smarket data from this chapter’s lab, except that it contains 1, 089\n",
        "weekly returns for 21 years, from the beginning of 1990 to the end of\n",
        "2010."
      ],
      "metadata": {
        "id": "I8W73Bam6Eo7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EikMSq7i6AuM",
        "outputId": "9cc6e8a6-50a9-4197-d185-d4b36b9f68f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ISLP\n",
            "  Downloading ISLP-0.4.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.13.1)\n",
            "Requirement already satisfied: pandas>=0.20 in /usr/local/lib/python3.10/dist-packages (from ISLP) (2.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from ISLP) (5.3.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.5.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ISLP) (1.4.2)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from ISLP) (0.14.4)\n",
            "Collecting lifelines (from ISLP)\n",
            "  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pygam (from ISLP)\n",
            "  Downloading pygam-0.9.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ISLP) (2.5.0+cu121)\n",
            "Collecting pytorch-lightning (from ISLP)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchmetrics (from ISLP)\n",
            "  Downloading torchmetrics-1.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20->ISLP) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20->ISLP) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20->ISLP) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2->ISLP) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->ISLP) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->ISLP) (24.1)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines->ISLP) (3.8.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines->ISLP) (1.7.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines->ISLP)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines->ISLP)\n",
            "  Downloading formulaic-1.0.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: progressbar2<5.0.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pygam->ISLP) (4.5.0)\n",
            "Collecting scipy>=0.9 (from ISLP)\n",
            "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m660.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->ISLP) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->ISLP) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->ISLP) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning->ISLP)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->ISLP) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->ISLP) (1.3.0)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines->ISLP)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.10.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning->ISLP) (75.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (3.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.13->ISLP) (1.16.0)\n",
            "Requirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from progressbar2<5.0.0,>=4.2.0->pygam->ISLP) (3.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ISLP) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (0.2.0)\n",
            "Downloading ISLP-0.4.0-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygam-0.9.1-py3-none-any.whl (522 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m522.0/522.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.5.1-py3-none-any.whl (890 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.6/890.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.0.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=36b25b63a9018a233b517e57be9f3d122ad60bc5ec624785d1613b2a41f2119f\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/cc/e0/ef2969164144c899fedb22b338f6703e2b9cf46eeebf254991\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: scipy, lightning-utilities, interface-meta, autograd-gamma, torchmetrics, pygam, formulaic, lifelines, pytorch-lightning, ISLP\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "Successfully installed ISLP-0.4.0 autograd-gamma-0.5.0 formulaic-1.0.2 interface-meta-1.3.0 lifelines-0.30.0 lightning-utilities-0.11.8 pygam-0.9.1 pytorch-lightning-2.4.0 scipy-1.11.4 torchmetrics-1.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ISLP"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(e) Repeat (d) using LDA."
      ],
      "metadata": {
        "id": "voPEv1ISByKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from ISLP import load_data\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import statsmodels.api as sm\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Load the Weekly dataset\n",
        "weekly_data = load_data('Weekly')\n",
        "\n",
        "# Define the predictors and the response variable\n",
        "X = weekly_data[['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume']]\n",
        "weekly_data['Direction_Numeric'] = weekly_data['Direction'].map({'Up': 1, 'Down': 0})\n",
        "\n",
        "# Check for NaN values and replace with a suitable value (e.g., 0)\n",
        "weekly_data['Direction_Numeric'].fillna(0, inplace=True)\n",
        "\n",
        "# Create a boolean mask for the training data (1990-2008)\n",
        "train_mask = weekly_data.Year <= 2008\n",
        "\n",
        "# Create a boolean mask for the test data (2009-2010)\n",
        "test_mask = weekly_data.Year >= 2009\n",
        "\n",
        "# Split the data into training and testing sets (same as in part (d))\n",
        "X_train = weekly_data.loc[train_mask, ['Lag2']]\n",
        "y_train = weekly_data.loc[train_mask, 'Direction_Numeric']\n",
        "X_test = weekly_data.loc[test_mask, ['Lag2']]\n",
        "y_test = weekly_data.loc[test_mask, 'Direction_Numeric']\n",
        "\n",
        "# Fit the LDA model using the training data\n",
        "lda_model = LinearDiscriminantAnalysis()\n",
        "lda_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_lda = lda_model.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix for the test data\n",
        "cm_lda = confusion_matrix(y_test, y_pred_lda)\n",
        "print(\"Confusion Matrix (Held-out data, LDA):\")\n",
        "print(cm_lda)\n",
        "\n",
        "# Calculate the accuracy for the test data\n",
        "accuracy_lda = accuracy_score(y_test, y_pred_lda)\n",
        "print(\"Overall Accuracy (Held-out data, LDA):\", accuracy_lda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUy3yeCw7p4P",
        "outputId": "f48e7324-c746-4405-a525-74ef398a1106"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Held-out data, LDA):\n",
            "[[ 9 34]\n",
            " [ 5 56]]\n",
            "Overall Accuracy (Held-out data, LDA): 0.625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-8f9837bc5e89>:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  weekly_data['Direction_Numeric'].fillna(0, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(f) Repeat (d) using QDA."
      ],
      "metadata": {
        "id": "htw_JhTWB9J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (same as in part (d))\n",
        "X_train = weekly_data.loc[train_mask, ['Lag2']]\n",
        "y_train = weekly_data.loc[train_mask, 'Direction_Numeric']\n",
        "X_test = weekly_data.loc[test_mask, ['Lag2']]\n",
        "y_test = weekly_data.loc[test_mask, 'Direction_Numeric']\n",
        "\n",
        "# Fit the QDA model using the training data\n",
        "qda_model = QuadraticDiscriminantAnalysis()\n",
        "qda_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_qda = qda_model.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix for the test data\n",
        "cm_qda = confusion_matrix(y_test, y_pred_qda)\n",
        "print(\"Confusion Matrix (Held-out data, QDA):\")\n",
        "print(cm_qda)\n",
        "\n",
        "# Calculate the accuracy for the test data\n",
        "accuracy_qda = accuracy_score(y_test, y_pred_qda)\n",
        "print(\"Overall Accuracy (Held-out data, QDA):\", accuracy_qda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjj7AW-cB9lH",
        "outputId": "eec07f80-e959-42cf-8b05-541facd41cae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Held-out data, QDA):\n",
            "[[ 0 43]\n",
            " [ 0 61]]\n",
            "Overall Accuracy (Held-out data, QDA): 0.5865384615384616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(g) Repeat (d) using KNN with K = 1."
      ],
      "metadata": {
        "id": "XoxDXV-yCB2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (same as in part (d))\n",
        "X_train = weekly_data.loc[train_mask, ['Lag2']]\n",
        "y_train = weekly_data.loc[train_mask, 'Direction_Numeric']\n",
        "X_test = weekly_data.loc[test_mask, ['Lag2']]\n",
        "y_test = weekly_data.loc[test_mask, 'Direction_Numeric']\n",
        "\n",
        "# Fit the KNN model with K=1 using the training data\n",
        "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix for the test data\n",
        "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
        "print(\"Confusion Matrix (Held-out data, KNN with K=1):\")\n",
        "print(cm_knn)\n",
        "\n",
        "# Calculate the accuracy for the test data\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "print(\"Overall Accuracy (Held-out data, KNN with K=1):\", accuracy_knn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g9ub88BCDt9",
        "outputId": "42bf4ede-6221-4ede-c19d-23aa22d95fff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Held-out data, KNN with K=1):\n",
            "[[22 21]\n",
            " [32 29]]\n",
            "Overall Accuracy (Held-out data, KNN with K=1): 0.49038461538461536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(h) Repeat (d) using naive Bayes."
      ],
      "metadata": {
        "id": "y0J6ecIxCJVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (same as in part (d))\n",
        "X_train = weekly_data.loc[train_mask, ['Lag2']]\n",
        "y_train = weekly_data.loc[train_mask, 'Direction_Numeric']\n",
        "X_test = weekly_data.loc[test_mask, ['Lag2']]\n",
        "y_test = weekly_data.loc[test_mask, 'Direction_Numeric']\n",
        "\n",
        "# Fit the Naive Bayes model using the training data\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix for the test data\n",
        "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
        "print(\"Confusion Matrix (Held-out data, Naive Bayes):\")\n",
        "print(cm_nb)\n",
        "\n",
        "# Calculate the accuracy for the test data\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "print(\"Overall Accuracy (Held-out data, Naive Bayes):\", accuracy_nb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hjbqQ9DCJst",
        "outputId": "a9212982-fa2a-4dd9-8e51-e6c0ed3df9c1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Held-out data, Naive Bayes):\n",
            "[[ 0 43]\n",
            " [ 0 61]]\n",
            "Overall Accuracy (Held-out data, Naive Bayes): 0.5865384615384616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(i) Which of these methods appears to provide the best results on\n",
        "this data?"
      ],
      "metadata": {
        "id": "1prSk1COCRnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA and Logistic Regression"
      ],
      "metadata": {
        "id": "tSdDP6XDCS7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(j) Experiment with different combinations of predictors, including\n",
        "possible transformations and interactions, for each of the\n",
        "methods. Report the variables, method, and associated confusion\n",
        "matrix that appears to provide the best results on the held\n",
        "out data. Note that you should also experiment with values for\n",
        "K in the KNN classifier."
      ],
      "metadata": {
        "id": "gNSwiaULCiIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Weekly dataset\n",
        "weekly_data = load_data('Weekly')\n",
        "\n",
        "# Create a numeric 'Direction' column\n",
        "weekly_data['Direction_Numeric'] = weekly_data['Direction'].map({'Up': 1, 'Down': 0})\n",
        "\n",
        "# Split the data into training and testing sets (using 2009-2010 as the test set)\n",
        "train_mask = weekly_data.Year <= 2008\n",
        "test_mask = weekly_data.Year >= 2009\n",
        "X_train = weekly_data.loc[train_mask, ['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume']]\n",
        "y_train = weekly_data.loc[train_mask, 'Direction_Numeric']\n",
        "X_test = weekly_data.loc[test_mask, ['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume']]\n",
        "y_test = weekly_data.loc[test_mask, 'Direction_Numeric']\n",
        "\n",
        "\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  return cm, accuracy\n",
        "\n",
        "\n",
        "# Experiment with different methods and predictors\n",
        "results = {}\n",
        "\n",
        "# Logistic Regression\n",
        "model_log = sm.Logit(y_train, sm.add_constant(X_train)).fit()\n",
        "y_pred_prob = model_log.predict(sm.add_constant(X_test))\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "cm_log = confusion_matrix(y_test, y_pred)\n",
        "accuracy_log = accuracy_score(y_test, y_pred)\n",
        "results['Logistic Regression (Lag1-Lag5, Volume)'] = (cm_log, accuracy_log)\n",
        "\n",
        "\n",
        "# LDA\n",
        "lda_model = LinearDiscriminantAnalysis()\n",
        "cm_lda, accuracy_lda = evaluate_model(lda_model, X_train, y_train, X_test, y_test)\n",
        "results['LDA (Lag1-Lag5, Volume)'] = (cm_lda, accuracy_lda)\n",
        "\n",
        "# QDA\n",
        "qda_model = QuadraticDiscriminantAnalysis()\n",
        "cm_qda, accuracy_qda = evaluate_model(qda_model, X_train, y_train, X_test, y_test)\n",
        "results['QDA (Lag1-Lag5, Volume)'] = (cm_qda, accuracy_qda)\n",
        "\n",
        "# KNN\n",
        "for k in [1, 3, 5, 7]:\n",
        "  knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "  cm_knn, accuracy_knn = evaluate_model(knn_model, X_train, y_train, X_test, y_test)\n",
        "  results[f'KNN (k={k}, Lag1-Lag5, Volume)'] = (cm_knn, accuracy_knn)\n",
        "\n",
        "# Naive Bayes\n",
        "nb_model = GaussianNB()\n",
        "cm_nb, accuracy_nb = evaluate_model(nb_model, X_train, y_train, X_test, y_test)\n",
        "results['Naive Bayes (Lag1-Lag5, Volume)'] = (cm_nb, accuracy_nb)\n",
        "\n",
        "\n",
        "# Find the best performing model\n",
        "best_model = max(results, key=lambda k: results[k][1])\n",
        "print(f\"Best Model: {best_model}\")\n",
        "print(f\"Confusion Matrix: \\n{results[best_model][0]}\")\n",
        "print(f\"Accuracy: {results[best_model][1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hgJM5SsFZmc",
        "outputId": "9cb91ba5-536f-4c21-f573-632c015508ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.681388\n",
            "         Iterations 4\n",
            "Best Model: KNN (k=7, Lag1-Lag5, Volume)\n",
            "Confusion Matrix: \n",
            "[[19 24]\n",
            " [26 35]]\n",
            "Accuracy: 0.5192307692307693\n"
          ]
        }
      ]
    }
  ]
}