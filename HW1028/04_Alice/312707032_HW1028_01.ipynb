{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4, Question 13  \n",
    "This question should be answered using the `Weekly` data set, which is part of the ISLP package. This data is similar in nature to the `Smarket` data from this chapterâ€™s lab, except that it contains 1,089 weekly returns for 21 years, from the beginning of 1990 to the end of 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "Weekly = load_data('Weekly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review of Part(d)  \n",
    "(d) Now fit the logistic regression model using a training data period from 1990 to 2008, with Lag2 as the only predictor.\n",
    "Compute the confusion matrix and the overall fraction of correct predictions for the held out data\n",
    "(that is, the data from 2009 and 2010)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Weekly[Weekly.Year <= 2008]\n",
    "test_data = Weekly[Weekly.Year > 2008]\n",
    "\n",
    "X_train = train_data[['Lag2']]\n",
    "y_train = train_data['Direction'].apply(lambda x: 1 if x == 'Up' else 0)\n",
    "\n",
    "X_test = test_data[['Lag2']]\n",
    "y_test = test_data['Direction'].apply(lambda x: 1 if x == 'Up' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part(e) \n",
    "(e) Repeat (d) using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Test Data - LDA):\n",
      " [[ 9 34]\n",
      " [ 5 56]]\n",
      "\n",
      "Overall Accuracy (Test Data - LDA): 0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Use LDA for classification\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X_train, y_train)\n",
    "lda_predictions = lda_model.predict(X_test)\n",
    "\n",
    "# Evaluate LDA model\n",
    "cm_lda = confusion_matrix(y_test, lda_predictions)\n",
    "print(\"Confusion Matrix (Test Data - LDA):\\n\", cm_lda)\n",
    "\n",
    "accuracy_lda = accuracy_score(y_test, lda_predictions)\n",
    "print(\"\\nOverall Accuracy (Test Data - LDA):\", accuracy_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part(f) \n",
    "(f) Repeat (d) using QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Test Data - QDA):\n",
      " [[ 0 43]\n",
      " [ 0 61]]\n",
      "\n",
      "Overall Accuracy (Test Data - QDA): 0.5865384615384616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Use QDA for classification\n",
    "qda_model = QuadraticDiscriminantAnalysis()\n",
    "qda_model.fit(X_train, y_train)\n",
    "qda_predictions = qda_model.predict(X_test)\n",
    "\n",
    "# Evaluate QDA model\n",
    "cm_qda = confusion_matrix(y_test, qda_predictions)\n",
    "print(\"Confusion Matrix (Test Data - QDA):\\n\", cm_qda)\n",
    "\n",
    "accuracy_qda = accuracy_score(y_test, qda_predictions)\n",
    "print(\"\\nOverall Accuracy (Test Data - QDA):\", accuracy_qda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part(g) \n",
    "(g) Repeat (d) using KNN with K=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Test Data - KNN):\n",
      " [[21 22]\n",
      " [30 31]]\n",
      "\n",
      "Overall Accuracy (Test Data - KNN): 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Use KNN with K=1 for classification\n",
    "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate KNN model\n",
    "cm_knn = confusion_matrix(y_test, knn_predictions)\n",
    "print(\"Confusion Matrix (Test Data - KNN):\\n\", cm_knn)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, knn_predictions)\n",
    "print(\"\\nOverall Accuracy (Test Data - KNN):\", accuracy_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part(h) \n",
    "(h) Repeat (d) using naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Test Data - Naive Bayes):\n",
      " [[ 0 43]\n",
      " [ 0 61]]\n",
      "\n",
      "Overall Accuracy (Test Data - Naive Bayes): 0.5865384615384616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Use Naive Bayes for classification\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate Naive Bayes model\n",
    "cm_nb = confusion_matrix(y_test, nb_predictions)\n",
    "print(\"Confusion Matrix (Test Data - Naive Bayes):\\n\", cm_nb)\n",
    "\n",
    "accuracy_nb = accuracy_score(y_test, nb_predictions)\n",
    "print(\"\\nOverall Accuracy (Test Data - Naive Bayes):\", accuracy_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part(i) \n",
    "(i) Which of these methods appears to provide the best results on this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "Based on the accuracy scores:\n",
    "- **LDA** provided the best results with an accuracy of **62.5%**.\n",
    "- Logistic Regression results were not directly provided in your snippet but should be evaluated similarly.\n",
    "- QDA, KNN, and Naive Bayes performed worse compared to LDA.\n",
    "\n",
    "To summarize, the LDA model is likely the best method for this dataset, followed by Logistic Regression (if its accuracy is higher than LDA). If you need further insights or to compute the accuracy for logistic regression, please let me know!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part(j) \n",
    "(j) Experiment with different combinations of predictors, including possible transformations and interactions, for each of the methods. Report the variables, method, and associated confusion matrix that appears to provide the best results on the held out data. Note that you should also experiment with values for K in the KNN classifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.6250\n",
      "Best Predictor Combination: ('Lag4',)\n",
      "Best K: 7\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Prepare the predictors and response variable\n",
    "X_train_full = train_data[['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5']]\n",
    "y_train = train_data['Direction'].apply(lambda x: 1 if x == 'Up' else 0)\n",
    "\n",
    "X_test_full = test_data[['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5']]\n",
    "y_test = test_data['Direction'].apply(lambda x: 1 if x == 'Up' else 0)\n",
    "\n",
    "# Generate all combinations of predictors\n",
    "predictor_combinations = [itertools.combinations(X_train_full.columns, i) for i in range(1, len(X_train_full.columns) + 1)]\n",
    "predictor_combinations = [item for sublist in predictor_combinations for item in sublist]  # Flatten the list\n",
    "\n",
    "# Initialize variables to store the best results\n",
    "best_accuracy = 0\n",
    "best_combination = None\n",
    "best_k = None\n",
    "\n",
    "# Function to evaluate KNN with different combinations of predictors and K values\n",
    "def evaluate_knn(X_train, y_train, X_test, y_test):\n",
    "    global best_accuracy, best_combination, best_k\n",
    "    for combination in predictor_combinations:\n",
    "        X_train_subset = X_train[list(combination)]\n",
    "        X_test_subset = X_test[list(combination)]\n",
    "        for k in [1, 3, 5, 7]:\n",
    "            knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "            knn_model.fit(X_train_subset, y_train)\n",
    "            knn_predictions = knn_model.predict(X_test_subset)\n",
    "            accuracy = accuracy_score(y_test, knn_predictions)\n",
    "\n",
    "            # Update the best results if the current accuracy is higher\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_combination = combination\n",
    "                best_k = k\n",
    "\n",
    "# Evaluate KNN with the defined function\n",
    "evaluate_knn(X_train_full, y_train, X_test_full, y_test)\n",
    "\n",
    "# Output the best results\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Best Predictor Combination: {best_combination}\")\n",
    "print(f\"Best K: {best_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "The analysis of the `Weekly` dataset using the K-Nearest Neighbors (KNN) classifier revealed that:\n",
    "\n",
    "- **Best Predictor**: The `Lag4` variable was identified as the most significant predictor, achieving the highest accuracy of **62.5%** when used alone.\n",
    "- **Optimal K Value**: A K value of **7** provided the best model performance, indicating effective averaging of the nearest neighbors' classifications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
